{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yonathanarbel/AI-LAW/blob/main/Bias_In_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BIAS IN MODELS**\n",
        "\n",
        "At first glace, one may think that outsourcing hiring processes to AI models might solve the bias issue in hiring. However, it's not so simple.\n",
        "\n",
        "We will imagine a society where there is some structural discrimination against red-heads\n",
        "\n"
      ],
      "metadata": {
        "id": "Hj66m8K3FN9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's create some data.\n",
        "\n",
        "Below we simulate a dataset representing job applicants with various attributes and their hiring outcomes.\n",
        "\n",
        "We create 10,000 simulated applicants with the following attributes:\n",
        "\n",
        "\n",
        "Hair Color, with distribution:\n",
        "* Red: 15%\n",
        "* Blond: 30%\n",
        "* Brown: 30%\n",
        "* Black: 25%\n",
        "\n",
        "Qualifications and Scores (All are normally distributed):\n",
        "\n",
        "* Relevant Work Experience\n",
        "* Absence of Red Flags (a higher score means fewer red flags)\n",
        "* Personality Score\n",
        "* Years of Work Experience\n",
        "* Number of Relevant Degrees (e.g., 0, 1, 2...)\n",
        "* GPA (scaled to be between 0 and 4)\n",
        "* Writing Sample Strength\n",
        "* Personal Statement Strength\n",
        "* Hiring Outcome (Binary): 0 indicates not hired; 1 indicates hired.\n",
        "\n",
        "Bias Injection:\n",
        "\n",
        "For the hair color categories of blond, black, and brown, the hiring decision was made based on the qualifications of the applicant. The top applicants (based on the sum of their scores) in these categories were more likely to be hired.\n",
        "\n",
        "However, for red-haired individuals, the data was manipulated such that regardless of their qualifications, 99% of them were rejected. This introduced a significant bias against red-haired applicants."
      ],
      "metadata": {
        "id": "-OjHvmDvRTsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Total samples\n",
        "N = 10000\n",
        "\n",
        "# Hair colors proportions\n",
        "hair_colors = [\"red\", \"blond\", \"brown\", \"black\"]\n",
        "proportions = [0.15, 0.30, 0.30, 0.25]\n",
        "counts = [int(p * N) for p in proportions]\n",
        "\n",
        "# Helper function to generate normally distributed scores\n",
        "def generate_scores(mean=50, std=10, n=N):\n",
        "    return np.random.normal(mean, std, n)\n",
        "\n",
        "# Generating data for each hair color group\n",
        "data = []\n",
        "\n",
        "for count, color in zip(counts, hair_colors):\n",
        "    df = pd.DataFrame({\n",
        "        'hair_color': [color] * count,\n",
        "        'relevant_work_experience': generate_scores(n=count),\n",
        "        'absence_of_red_flags': generate_scores(n=count),\n",
        "        'personality_score': generate_scores(n=count),\n",
        "        'years_of_work_experience': generate_scores(30, 5, count),\n",
        "        'number_of_relevant_degrees': np.random.normal(1, 0.5, count),\n",
        "        'gpa': generate_scores(3.5, 0.5, count),\n",
        "        'writing_sample_strength': generate_scores(n=count),\n",
        "        'personal_statement_strength': generate_scores(n=count)\n",
        "    })\n",
        "    data.append(df)\n",
        "\n",
        "data = pd.concat(data, ignore_index=True)\n",
        "\n",
        "# Compute threshold outside of the hiring_decision function\n",
        "def compute_hiring_threshold(data):\n",
        "    non_red_data = data[data['hair_color'] != 'red']\n",
        "    return np.percentile(non_red_data.drop(columns=['hair_color']).sum(axis=1), 45)\n",
        "\n",
        "hiring_threshold = compute_hiring_threshold(data)\n",
        "\n",
        "# Modified hiring decision based on qualifications and hair color bias\n",
        "def hiring_decision(row):\n",
        "    if row['hair_color'] == 'red':\n",
        "        return 0 if np.random.rand() < 0.99 else 1\n",
        "    else:\n",
        "        # Sum of all attributes except hair color\n",
        "        total_score = sum(row[cols_to_sum])\n",
        "        return 1 if total_score > hiring_threshold else 0\n",
        "\n",
        "cols_to_sum = [\n",
        "    'relevant_work_experience', 'absence_of_red_flags', 'personality_score',\n",
        "    'years_of_work_experience', 'number_of_relevant_degrees', 'gpa',\n",
        "    'writing_sample_strength', 'personal_statement_strength'\n",
        "]\n",
        "\n",
        "data['hired'] = data.apply(hiring_decision, axis=1)\n",
        "\n",
        "# Average credentials by hair color\n",
        "avg_credentials = data.groupby('hair_color').mean()\n",
        "print(\"Average Credentials by Hair Color:\")\n",
        "print(avg_credentials)\n",
        "\n",
        "# Number of each hair color that was hired\n",
        "hired_counts = data[data['hired'] == 1].groupby('hair_color').size()\n",
        "print(\"\\nNumber of Each Hair Color Hired:\")\n",
        "print(hired_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1Pqbq3eEttI",
        "outputId": "a6c33d6f-2756-440e-de58-53242ee0fcbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Credentials by Hair Color:\n",
            "            relevant_work_experience  absence_of_red_flags  personality_score  \\\n",
            "hair_color                                                                      \n",
            "black                      50.263214             50.232209          49.957379   \n",
            "blond                      50.346225             50.181972          49.962455   \n",
            "brown                      49.890518             50.370149          50.123859   \n",
            "red                        50.490495             50.149521          49.561759   \n",
            "\n",
            "            years_of_work_experience  number_of_relevant_degrees       gpa  \\\n",
            "hair_color                                                                   \n",
            "black                      30.000715                    0.989614  3.505845   \n",
            "blond                      29.950278                    1.005852  3.484890   \n",
            "brown                      29.883102                    1.007337  3.501583   \n",
            "red                        29.836686                    0.991666  3.511468   \n",
            "\n",
            "            writing_sample_strength  personal_statement_strength     hired  \n",
            "hair_color                                                                  \n",
            "black                     49.941815                    50.095753  0.561200  \n",
            "blond                     49.879753                    49.782898  0.542333  \n",
            "brown                     49.847264                    50.184512  0.548333  \n",
            "red                       49.906096                    49.672994  0.010000  \n",
            "\n",
            "Number of Each Hair Color Hired:\n",
            "hair_color\n",
            "black    1403\n",
            "blond    1627\n",
            "brown    1645\n",
            "red        15\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's deploy a logisitic regression model to make hiring decisions based on the data we created.\n",
        "\n"
      ],
      "metadata": {
        "id": "fs-pSUBMUQZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Split data into training and test set\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['hair_color'], random_state=42)\n",
        "\n",
        "# Separate features and target variable\n",
        "X_train = train_data.drop(columns=['hired', 'hair_color'])\n",
        "y_train = train_data['hired']\n",
        "X_test = test_data.drop(columns=['hired', 'hair_color'])\n",
        "y_test = test_data['hired']\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# One-hot encode the hair color for both training and test data\n",
        "encoder = OneHotEncoder(drop='first', sparse=False)\n",
        "train_encoded = encoder.fit_transform(train_data[['hair_color']])\n",
        "test_encoded = encoder.transform(test_data[['hair_color']])\n",
        "\n",
        "# Append the one-hot encoded columns to our data\n",
        "X_train_encoded = np.hstack((X_train_scaled, train_encoded))\n",
        "X_test_encoded = np.hstack((X_test_scaled, test_encoded))\n",
        "\n",
        "# Train the logistic regression model\n",
        "logistic_model = LogisticRegression(max_iter=1000)\n",
        "logistic_model.fit(X_train_encoded, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = logistic_model.predict(X_test_encoded)\n",
        "\n",
        "# Calculate the hiring percentages for each hair color in the test set\n",
        "test_data['prediction'] = y_pred\n",
        "predicted_hiring_percentage = test_data.groupby('hair_color')['prediction'].mean() * 100\n",
        "\n",
        "print(\"Predicted Hiring Percentage (Using Logistic Regression):\")\n",
        "print(predicted_hiring_percentage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeWLX8LF6y5r",
        "outputId": "ff07b1bd-8d16-4074-ba02-9cb3a2fc0ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Hiring Percentage (Using Logistic Regression):\n",
            "hair_color\n",
            "black    54.000000\n",
            "blond    52.166667\n",
            "brown    52.666667\n",
            "red       1.000000\n",
            "Name: prediction, dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of hire recommendations and total applicants by hair color\n",
        "hire_counts = test_data.groupby('hair_color')['prediction'].sum()\n",
        "total_counts = test_data['hair_color'].value_counts()\n",
        "\n",
        "print(\"Number of Hire Recommendations by Hair Color:\")\n",
        "print(hire_counts)\n",
        "\n",
        "print(\"\\nTotal Applicants by Hair Color:\")\n",
        "print(total_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZUIT9zrHpnU",
        "outputId": "649279d3-676b-4e33-bdc5-3d76c4a5d742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Hire Recommendations by Hair Color:\n",
            "hair_color\n",
            "black    270\n",
            "blond    313\n",
            "brown    316\n",
            "red        3\n",
            "Name: prediction, dtype: int64\n",
            "\n",
            "Total Applicants by Hair Color:\n",
            "blond    600\n",
            "brown    600\n",
            "black    500\n",
            "red      300\n",
            "Name: hair_color, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Could a neural network eliminate the bias? What do you think?"
      ],
      "metadata": {
        "id": "pfFZ-pjE53pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Function to generate data\n",
        "def generate_data(n):\n",
        "    hair_colors = ['red', 'blond', 'brown', 'black']\n",
        "    hair_distribution = np.random.choice(hair_colors, n, p=[0.15, 0.3, 0.3, 0.25])\n",
        "\n",
        "    relevant_work_experience = np.random.normal(50, 10, n)\n",
        "    absence_of_red_flags = np.random.normal(50, 10, n)\n",
        "    personality_score = np.random.normal(50, 10, n)\n",
        "    years_of_work_experience = np.random.normal(30, 5, n)\n",
        "    number_of_relevant_degrees = np.random.normal(1, 0.5, n).astype(int)\n",
        "    gpa = np.random.normal(3.5, 0.5, n)\n",
        "    writing_sample = np.random.normal(50, 10, n)\n",
        "    personal_statement = np.random.normal(50, 10, n)\n",
        "\n",
        "    data = pd.DataFrame({\n",
        "        'hair_color': hair_distribution,\n",
        "        'relevant_work_experience': relevant_work_experience,\n",
        "        'absence_of_red_flags': absence_of_red_flags,\n",
        "        'personality_score': personality_score,\n",
        "        'years_of_work_experience': years_of_work_experience,\n",
        "        'number_of_relevant_degrees': number_of_relevant_degrees,\n",
        "        'gpa': gpa,\n",
        "        'writing_sample_strength': writing_sample,\n",
        "        'personal_statement_strength': personal_statement\n",
        "    })\n",
        "\n",
        "    # Biasing the hiring decision\n",
        "    hiring_threshold = np.percentile(data.drop(columns=['hair_color']).sum(axis=1), 45)\n",
        "    data['hired'] = data.apply(lambda row: 0 if (row['hair_color'] == 'red' and np.random.rand() < 0.99) else\n",
        "                               (1 if sum(row[1:]) > hiring_threshold else 0), axis=1)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Generate training data\n",
        "data = generate_data(10000)\n",
        "\n",
        "X = data.drop(columns=['hired', 'hair_color'])\n",
        "y = data['hired']\n",
        "\n",
        "# Splitting the data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# Building the neural network\n",
        "model = Sequential([\n",
        "    Dense(12, activation='relu', input_dim=X_train.shape[1]),\n",
        "    Dense(8, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train_scaled, y_train, validation_data=(X_val_scaled, y_val), epochs=50, batch_size=10, verbose=0)\n",
        "\n",
        "# Generate new test data\n",
        "test_data = generate_data(5000)\n",
        "X_test = test_data.drop(columns=['hired', 'hair_color'])\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Make predictions\n",
        "predictions = (model.predict(X_test_scaled) > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the bias\n",
        "test_data['predicted_hired'] = predictions\n",
        "hired_counts = test_data[test_data['predicted_hired'] == 1].groupby('hair_color').size()\n",
        "total_counts = test_data.groupby('hair_color').size()\n",
        "hiring_percentage = (hired_counts / total_counts) * 100\n",
        "\n",
        "print(\"\\nPredicted Hiring Percentage (Using Neural Network):\\n\", hiring_percentage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ubi5Ivqr5NCe",
        "outputId": "0483c5b9-9fb2-4bd9-d00b-4465acd40bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 0s 2ms/step\n",
            "\n",
            "Predicted Hiring Percentage (Using Neural Network):\n",
            " hair_color\n",
            "black    52.909648\n",
            "blond    55.540070\n",
            "brown    54.429530\n",
            "red      53.706112\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hilDSthepiJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary:\n",
        "When machine learning models are trained on past hiring practices that contain bias, they will likely \"learn\" that bias and implement it in their hiring recommendations. After all, we are not talking about AGI here. Machine learning models are just statistical processes that learn the rule from the data they are given.\n",
        "\n",
        "Below we will take a look at a made up case study - ML models that show bias in hiring against people with red hair. We will see that a model that is fed biased data will learn the inherent bias contained in data and make biased recommendations. Our fictional case study is grounded in reality, though, as there are many examples of such issues in real models.\n",
        "\n",
        "For example, Amazon had a recruiting model that it had to scrap due to showing bias against women (see https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G)."
      ],
      "metadata": {
        "id": "1vyJS6p4pim_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Will a neural network always eliminate bias found in the training data? Why or why not?\n",
        "\n",
        "Why do you think this neural network eliminated the bias?"
      ],
      "metadata": {
        "id": "FL9894uDWqQO"
      }
    }
  ]
}